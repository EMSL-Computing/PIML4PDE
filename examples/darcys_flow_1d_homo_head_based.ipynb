{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d739db8-bb3d-4447-8108-c66934a672f6",
   "metadata": {},
   "source": [
    "### **Problem Statement:** \n",
    "We aim to solve **1D steady-state flow problems** in homogeneous porous media using the **Physics-Informed Neural Networks (PINN)** approach for solving PDEs, implemented with the JAX library. \n",
    "\n",
    "\n",
    "\n",
    "### **Domain**:\n",
    "$$ \n",
    "\\Omega = \\{ x \\mid 0 \\leq x \\leq L \\}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "### **Governing Equation**:\n",
    "The 1D steady-state flow in homogeneous porous media is governed by Darcy's law as follows:\n",
    "<!-- $$ \n",
    "\\frac{\\partial}{\\partial x} \\left( K \\frac{\\partial h}{\\partial x} \\right) = 0, \\quad \\text{in } \\Omega.\n",
    "$$ \n",
    "\n",
    "For a homogeneous medium where hydraulic conductivity, K is constant, this simplifies to: -->\n",
    "$$ \n",
    "\\frac{\\partial^2 h}{\\partial x^2} = 0, \\quad \\text{in } \\Omega.\n",
    "$$ \n",
    "\n",
    "\n",
    "\n",
    "### **Boundary Conditions**\n",
    "\n",
    "**Dirichlet Boundary Conditions** (Prescribed pressure on the left and right boundaries):  \n",
    "$$ \n",
    "h(0) = h_1, \\quad h(L) = h_2.\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "### **Objective**:\n",
    "We solve this problem using Physics-Informed Neural Networks (PINN) to predict the head, h(x),  across the domain and compare it with the analytical solution for the same configuration.\n",
    "\n",
    "\n",
    "---\n",
    "**Developed by**:\n",
    "Lal Mamud, Postdoc - Subsurface Modeler, Environmental Subsurface Science Group, Energy & Environment Division, Pacific Northwest National Laboratory, Richland, WA, USA.\n",
    "\n",
    "**Mentors**:\n",
    "Maruti K. Mudunuru and Satish Karra\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81477b1f-9873-439c-9007-a353fc172a28",
   "metadata": {},
   "source": [
    "## 1. Import required Python libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3a0a4a1-1590-4350-ae66-96f46d147f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import random, jit, grad, vmap, jacfwd, jacrev\n",
    "import optax\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import matplotlib as mpl\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42682b69-8918-4aa9-bb51-677c07d5104a",
   "metadata": {},
   "source": [
    "## 2. Define Domain and Boundary Conditions, Generate Collocation Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d330436f-e3e9-4d0b-8841-2b2326f2fbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "xmin = 0.0  # Left boundary of the domain\n",
    "xmax = 1.0  # Right boundary of the domain\n",
    "\n",
    "lb_head = 1  # Head at the left boundary\n",
    "rb_head = 0.9  # Head at the right boundary\n",
    "bcs = [lb_head, rb_head]  # Boundary conditions as a list\n",
    "\n",
    "n_colloc = 100  # Number of collocation points\n",
    "\n",
    "# Generate random collocation points within the domain\n",
    "key = jax.random.PRNGKey(0)  # Random seed\n",
    "#x_colloc = jnp.linspace(xmin, xmax, n_colloc).reshape(-1, 1)\n",
    "x_colloc = jax.random.uniform(key, shape=(n_colloc, 1), minval=xmin, maxval=xmax)\n",
    "\n",
    "# # Plot the random collocation points\n",
    "# plt.figure(figsize = (5, 4), dpi = 150)\n",
    "# #plt.scatter(x_colloc, jnp.zeros_like(x_colloc), color='black', label='Collocation Points', s=5)\n",
    "# plt.xlabel('$x$')\n",
    "# plt.legend()\n",
    "# #plt.ylabel('Random Points (Plotted on $y=0$)')\n",
    "# plt.title('Random Collocation Points in 1D Domain')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65cd2f51-931a-4e54-b368-81e10d582af4",
   "metadata": {},
   "source": [
    "## 3. Define PDE Residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6bb53c22-83a0-4433-aca5-815362ab323a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDE Residual for 1D Darcy's Flow\n",
    "def pde_residual_1d_darcy(x, h):\n",
    "    \"\"\"\n",
    "    Compute the PDE residual for Darcy's flow.\n",
    "\n",
    "    Args:\n",
    "        h Lambda function representing the neural network solution h(x).\n",
    "        x: Collocation points (array of shape Nx1).\n",
    "    \n",
    "    Returns:\n",
    "        pde_res: PDE residual (array of shape Nx1).\n",
    "    \"\"\"\n",
    "\n",
    "    h_x = lambda x: vmap(jacfwd(h))(x)  # First derivative\n",
    "    \n",
    "    h_xx = lambda x: vmap(jacrev(h_x))(x)  # Second derivative\n",
    "    \n",
    "    pde_res = h_xx(x).reshape(-1, 1)\n",
    "    \n",
    "    return pde_res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b58017-c4ef-4437-a772-f388193b0648",
   "metadata": {},
   "source": [
    "## 4. Define Neural Network Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8116f925-cc88-4c8d-a521-2f958e44d970",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to initialize parameters of the neural network (weights and biases)\n",
    "def init_mlp(layers, key):\n",
    "    \"\"\"\n",
    "    Initialize the neural network using Xavier initialization.\n",
    "\n",
    "    Args:\n",
    "        layers: List defining the number of nodes in each layer (e.g., [1, 50, 50, 1]).\n",
    "        key: Random key for initialization.\n",
    "    \n",
    "    Returns:\n",
    "        params: Initialized weights and biases for the network.\n",
    "    \"\"\"\n",
    "    params = []\n",
    "    for i in range(len(layers) - 1):\n",
    "        key, subkey = random.split(key)\n",
    "        bound = jnp.sqrt(6. / (layers[i] + layers[i+1]))\n",
    "        weights = random.uniform(subkey, (layers[i], layers[i+1]), minval=-bound, maxval=bound)\n",
    "        biases = jnp.zeros(layers[i+1])\n",
    "        params.append((weights, biases))\n",
    "    return params\n",
    "\n",
    "\n",
    "\n",
    "# Define Neural Network Architecture \n",
    "def neural_net(params, coord):\n",
    "    \"\"\"\n",
    "    Forward pass through the neural network.\n",
    "\n",
    "    Args:\n",
    "        params: Neural network parameters (list of weights and biases).\n",
    "        coord: Input coordinates (array of shape Nx1).\n",
    "    \n",
    "    Returns:\n",
    "        h_nn: Output of the neural network.\n",
    "    \"\"\"\n",
    "    for w, b in params:\n",
    "        h_nn = jnp.dot(coord, w) + b\n",
    "        coord = jnp.tanh(h_nn)  # Activation function\n",
    "    return h_nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd28c5b1-484a-4cd8-93e2-bc903ea636eb",
   "metadata": {},
   "source": [
    "## 5. Define Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "635bd372-60b9-4c4b-9bbf-6b564cc3c795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss Function\n",
    "def loss_func(params, x, bcs):\n",
    "    \"\"\"\n",
    "    Compute the total loss for the PINN.\n",
    "\n",
    "    Args:\n",
    "        params: Neural network parameters.\n",
    "        x: Collocation points (array of shape Nx1).\n",
    "        bcs: Boundary conditions [left_head, right_head].\n",
    "    \n",
    "    Returns:\n",
    "        loss: Total loss (scalar).\n",
    "    \"\"\"\n",
    "\n",
    "    h = lambda x: neural_net(params, x)\n",
    "    \n",
    "    # PDE residual loss\n",
    "    #pde_res = pde_residual_1d_darcy(params, x)\n",
    "    pde_res = pde_residual_1d_darcy(x, h)\n",
    "    \n",
    "    pde_loss = jnp.mean(pde_res**2)  # Ensure this is scalar\n",
    "\n",
    "    # Boundary condition loss\n",
    "    left_bc_loss = (h(xmin) - bcs[0])**2\n",
    "    \n",
    "    right_bc_loss = (h(xmax) - bcs[1])**2\n",
    "    \n",
    "    bc_loss = left_bc_loss + right_bc_loss  # Ensure scalar addition\n",
    "\n",
    "    # Total loss\n",
    "    loss = pde_loss + bc_loss\n",
    "    \n",
    "    return jnp.sum(loss)  # Return scalar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286ee87a-e510-4395-bd1c-df448422a30b",
   "metadata": {},
   "source": [
    "## 6. Define Hyperparameters and Training Loop\n",
    "This cell contains the training loop for the Physics-Informed Neural Network (PINN). It includes functions and code to update the network parameters, compute the loss, track training progress, and identify the best-performing model during the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2c29272e-29ef-4f9a-b92f-75ccd666f0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training PINN\n",
    "n_hl = 3  # Number of hidden layers\n",
    "n_nodes = 50  # Number of nodes per layer\n",
    "lr = 1E-2  # Learning rate\n",
    "epoch = 5000  # Number of epochs\n",
    "\n",
    "layers = [1, n_nodes, 1]  # Neural network architecture\n",
    "soln_type = 1  # Solution type: 0 = homogeneous, 1 = heterogeneous\n",
    "\n",
    "# Initialize neural network\n",
    "key = random.PRNGKey(1234)\n",
    "params = init_mlp(layers, key)\n",
    "\n",
    "# Initialize optimizer\n",
    "optimizer = optax.adam(learning_rate=lr)\n",
    "opt_state = optimizer.init(params)\n",
    "\n",
    "\n",
    "# Parameters update function\n",
    "@jit\n",
    "def update(params, opt_state, x):\n",
    "    \"\"\"\n",
    "    Perform one optimization step.\n",
    "\n",
    "    Args:\n",
    "        params: Neural network parameters.\n",
    "        opt_state: Optimizer state.\n",
    "        x: Collocation points.\n",
    "    \n",
    "    Returns:\n",
    "        value: Current loss.\n",
    "        params: Updated parameters.\n",
    "        opt_state: Updated optimizer state.\n",
    "    \"\"\"\n",
    "    value, grads = jax.value_and_grad(loss_func)(params, x, bcs)\n",
    "    updates, opt_state = optimizer.update(grads, opt_state)\n",
    "    params = optax.apply_updates(params, updates)\n",
    "    return value, params, opt_state\n",
    "\n",
    "\n",
    "#%% Training loop\n",
    "# Initialize lists to track all losses and epochs\n",
    "all_losses = []\n",
    "all_epochs = []\n",
    "\n",
    "# Initialize tracking variables\n",
    "min_loss = jnp.inf\n",
    "best_params = None\n",
    "\n",
    "# for i in range(epoch + 1):\n",
    "#     loss, params, opt_state = update(params, opt_state, x_colloc)\n",
    "#     all_losses.append(loss)\n",
    "#     all_epochs.append(i)\n",
    "#     if loss < min_loss:\n",
    "#         min_loss = loss\n",
    "#         best_params = params\n",
    "#         best_iteration = i\n",
    "#     if i % 100 == 0:\n",
    "#         print(f\"Epoch {i}: Loss = {loss:.4e}\")\n",
    "\n",
    "# print(f\" \")\n",
    "# print(f\"Best Model:\")\n",
    "# print(f\"Best loss: {min_loss:.4e} at iteration {best_iteration}\")\n",
    "# print(f\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100ebf4a-deb2-4452-a32c-31c5367ccd6a",
   "metadata": {},
   "source": [
    "## 7. Plot pinn loss during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "31b20afa-b574-41ea-adc4-0b11683e4945",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pinn_training(all_losses, all_epochs):\n",
    "    plt.figure(figsize = (5, 4), dpi = 150)\n",
    "    plt.semilogy(all_epochs, all_losses, '-r', markersize = 4, linewidth = 1.0)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    #plt.legend(prop={\"size\": fontsize_legend}, loc=\"best\")\n",
    "    plt.xlim(min(all_epochs), max(all_epochs))\n",
    "    plt.tight_layout()\n",
    "    \n",
    "#plot_pinn_training(all_losses, all_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6299d17c-4a74-46f0-8605-d98acfd51715",
   "metadata": {},
   "source": [
    "## 8. PINN prediction and plotting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1053a2b6-edb7-41e2-99fc-2859d50ddc40",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx = 20\n",
    "x = np.linspace(xmin, xmax, nx)\n",
    "x = np.linspace(xmin, xmax, nx).reshape(-1, 1)  # Reshape to (nx, 1) to match neural_net input\n",
    "\n",
    "\n",
    "# Predict head using the trained neural network\n",
    "# h_pinn = neural_net(best_params, x)  # Output will be (nx, 1)\n",
    "# print(h_pinn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c210595f-eaa7-4277-b068-d9b163b0a9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_head_solutions(coords, pinn_head):\n",
    "    plt.figure(figsize = (5, 4), dpi = 150)\n",
    "    #plt.plot(coords, head_exact, color='Black', linestyle='-', linewidth = 1.25, label=\"Analytical\")\n",
    "    plt.plot(coords, pinn_head, '--', color='red', markersize = 4,  markerfacecolor = 'green', linewidth = 1.25, label=\"PINN\")\n",
    "    plt.xlabel(\"X [L]\")\n",
    "    plt.ylabel(\"Head [L]\")\n",
    "    plt.title(\"PINN solution for head\")\n",
    "    plt.xlim(np.min(coords), np.max(coords))\n",
    "    plt.tight_layout()\n",
    "#plot_head_solutions(x, h_pinn )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd28673-ff24-4e11-a5aa-91f88e0fffcd",
   "metadata": {},
   "source": [
    "## 9. Solution verifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2beabc18-3745-4ab1-8c5b-59d5ea874a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# analytical solution of this homogeneous 1D case\n",
    "def exact_solution_homo(x_coords):\n",
    "    head_exact = -0.1*x_coords + 1\n",
    "    return head_exact  \n",
    "\n",
    "# h_exact = exact_solution_homo(x)\n",
    "# print(h_exact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "37e89507-5661-43cf-82a2-162528fb62e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_head_solutions_as_pinn(coords, pinn_head, exact_head):\n",
    "    plt.figure(figsize = (5, 4), dpi = 150)\n",
    "    plt.plot(coords, exact_head, color='Black', linestyle='-', linewidth = 1.0, label=\"Analytical\")\n",
    "    plt.plot(coords, pinn_head, '--', color='red', markersize = 4,  markerfacecolor = 'green', linewidth = 1.5, label=\"PINN\")\n",
    "    plt.xlabel(\"X [L]\")\n",
    "    plt.ylabel(\"Head [L]\")\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.xlim(np.min(coords), np.max(coords))\n",
    "    plt.tight_layout()\n",
    "#plot_head_solutions_as_pinn(x, h_pinn, h_exact)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76f6c56-97a7-46a8-b0d4-41054b277425",
   "metadata": {},
   "source": [
    "## 10. Error analysis between the analytical solution and PINN prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "68ef66bf-7814-4e64-87d1-b52bf180fc0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Score: 1.0000\n",
      "Root Mean Squared Error (RMSE): 0.0000\n"
     ]
    }
   ],
   "source": [
    "# Analytical solution and PINN predictions are already 1D\n",
    "analytical_Pr = h_exact.flatten()  # Flatten the analytical solution (if necessary)\n",
    "pinn_Pr = h_pinn.flatten()  # Flatten the PINN predictions (if necessary)\n",
    "\n",
    "# Perform regression\n",
    "reg = LinearRegression()\n",
    "reg.fit(analytical_Pr.reshape(-1, 1), pinn_Pr)  # Fit the model\n",
    "\n",
    "# Predict using the regression model\n",
    "y_pred = reg.predict(analytical_Pr.reshape(-1, 1))\n",
    "\n",
    "# Calculate R^2 score\n",
    "r2 = r2_score(pinn_Pr, y_pred)\n",
    "\n",
    "# Calculate RMSE\n",
    "mse = mean_squared_error(pinn_Pr, y_pred)  # Mean Squared Error\n",
    "rmse = np.sqrt(mse)  # Root Mean Squared Error\n",
    "\n",
    "# Print results\n",
    "print(f\"R^2 Score: {r2:.4f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "657202bd-bf79-4e4d-979f-2d280a68de7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #%% Plotting Regression\n",
    "# plt.figure(figsize = (5, 4), dpi = 150)\n",
    "# plt.scatter(analytical_Pr, pinn_Pr, label=\"Data Points\", color=\"blue\", alpha=0.7)\n",
    "# plt.plot(analytical_Pr, y_pred, label=\"Regression Line\", color=\"red\", linewidth=2)\n",
    "\n",
    "# # Add annotations for RMSE and R^2\n",
    "# plt.text(\n",
    "#     0.05,\n",
    "#     0.95,\n",
    "#     f\"$R^2$ = {r2:.4f}\\nRMSE = {rmse:.4f}\",\n",
    "#     transform=plt.gca().transAxes,\n",
    "#     fontsize=12,\n",
    "#     verticalalignment=\"top\",\n",
    "#     bbox=dict(boxstyle=\"round\", facecolor=\"white\", alpha=0.8),\n",
    "# )\n",
    "\n",
    "# plt.xlabel(\"Analytical Solution\")\n",
    "# plt.ylabel(\"PINN Prediction\")\n",
    "# plt.title(\"Regression Plot: Analytical vs. PINN Predictions\")\n",
    "# plt.legend(loc=\"lower right\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "989fedfd-cfa0-4ff6-89b1-2c14e33aa1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #%% Plotting Error\n",
    "# # Calculate percentage error\n",
    "# error_percentage = 100 * (analytical_Pr - pinn_Pr) / analytical_Pr\n",
    "# plt.figure(figsize = (5, 4), dpi = 150)\n",
    "# plt.plot(x, error_percentage, label=\"Error (%)\", color=\"red\", marker=\"o\")\n",
    "# plt.xlabel(\"$x$\")\n",
    "# plt.ylabel(\"$Error (\\%)$\")\n",
    "# plt.title(\"Percentage Error Between Analytical and PINN Solution\")\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b41393-d44f-4db4-b5cf-c13fb78df4a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
